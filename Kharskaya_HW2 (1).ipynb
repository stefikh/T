{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KslYmMKMLY7V"
      },
      "source": [
        "#HW2 - Transliteration\n",
        "\n",
        "Please send this to dlnlp2023@mail.ru with subject \"Surname_HW2\"\n",
        "\n",
        "Deadline: 16.01.2023\n",
        "\n",
        "Харская Стефания Андреевна БКЛ212\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeC1UiR2LXiV"
      },
      "source": [
        "In this task you are required to solve the transliteration problem of names from English to Russian. Transliteration of a string means writing this string using the alphabet of another language with the preservation of pronunciation, although not always.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIr56czmR5FZ"
      },
      "source": [
        "## Basic algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lf3-DST1YBx",
        "outputId": "2fc5438b-f83a-4e94-f253-69715a592aff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-20 10:08:36--  https://github.com/s-nlp/filimdb_evaluation/raw/master/TRANSLIT.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/s-nlp/filimdb_evaluation/master/TRANSLIT.tar.gz [following]\n",
            "--2024-11-20 10:08:36--  https://raw.githubusercontent.com/s-nlp/filimdb_evaluation/master/TRANSLIT.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1546458 (1.5M) [application/octet-stream]\n",
            "Saving to: ‘TRANSLIT.tar.gz’\n",
            "\n",
            "TRANSLIT.tar.gz     100%[===================>]   1.47M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-11-20 10:08:36 (35.7 MB/s) - ‘TRANSLIT.tar.gz’ saved [1546458/1546458]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/s-nlp/filimdb_evaluation/raw/master/TRANSLIT.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "a1wUwZbT1lDd"
      },
      "outputs": [],
      "source": [
        "!gunzip TRANSLIT.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pg5z4ezh1zO6"
      },
      "outputs": [],
      "source": [
        "!tar -xf TRANSLIT.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7p9Nac-4X8C"
      },
      "source": [
        "### Evaluation code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aOz9Miec58Tb"
      },
      "outputs": [],
      "source": [
        "PREDS_FNAME = \"preds_translit_baseline.tsv\"\n",
        "SCORED_PARTS = ('train', 'dev', 'train_small', 'dev_small', 'test')\n",
        "TRANSLIT_PATH = \"TRANSLIT\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SdbtMBxd52yX"
      },
      "outputs": [],
      "source": [
        "import codecs\n",
        "from pandas import read_csv\n",
        "from typing import List\n",
        "\n",
        "def load_dataset(data_dir_path=None, parts: List[str] = SCORED_PARTS):\n",
        "    part2ixy = {}\n",
        "    for part in parts:\n",
        "        path = os.path.join(data_dir_path, f'{part}.tsv')\n",
        "        with open(path, 'r', encoding='utf-8') as rf:\n",
        "            # first line is a header of the corresponding columns\n",
        "            lines = rf.readlines()[1:]\n",
        "            col_count = len(lines[0].strip('\\n').split('\\t'))\n",
        "            if col_count == 2:\n",
        "                strings, transliterations = zip(\n",
        "                    *list(map(lambda l: l.strip('\\n').split('\\t'), lines))\n",
        "                )\n",
        "            elif col_count == 1:\n",
        "                strings = list(map(lambda l: l.strip('\\n'), lines))\n",
        "                transliterations = None\n",
        "            else:\n",
        "                raise ValueError(\"wrong amount of columns\")\n",
        "        part2ixy[part] = (\n",
        "            [f'{part}/{i}' for i in range(len(strings))],\n",
        "            strings, transliterations,\n",
        "        )\n",
        "    return part2ixy\n",
        "\n",
        "\n",
        "def load_transliterations_only(data_dir_path=None, parts: List[str] = SCORED_PARTS):\n",
        "    part2iy = {}\n",
        "    for part in parts:\n",
        "        path = os.path.join(data_dir_path, f'{part}.tsv')\n",
        "        with open(path, 'r', encoding='utf-8') as rf:\n",
        "            # first line is a header of the corresponding columns\n",
        "            lines = rf.readlines()[1:]\n",
        "            col_count = len(lines[0].strip('\\n').split('\\t'))\n",
        "            n_lines = len(lines)\n",
        "            if col_count == 2:\n",
        "                transliterations = [l.strip('\\n').split('\\t')[1] for l in lines]\n",
        "            elif col_count == 1:\n",
        "                transliterations = None\n",
        "            else:\n",
        "                raise ValueError(\"Wrong amount of columns\")\n",
        "        part2iy[part] = (\n",
        "            [f'{part}/{i}' for i in range(n_lines)],\n",
        "            transliterations,\n",
        "        )\n",
        "    return part2iy\n",
        "\n",
        "\n",
        "def save_preds(preds, preds_fname):\n",
        "    \"\"\"\n",
        "    Save classifier predictions in format appropriate for scoring.\n",
        "    \"\"\"\n",
        "    with codecs.open(preds_fname, 'w') as outp:\n",
        "        for idx, preds in preds:\n",
        "            print(idx, *preds, sep='\\t', file=outp)\n",
        "    print('Predictions saved to %s' % preds_fname)\n",
        "\n",
        "\n",
        "def load_preds(preds_fname, top_k=1):\n",
        "    \"\"\"\n",
        "    Load classifier predictions in format appropriate for scoring.\n",
        "    \"\"\"\n",
        "    kwargs = {\n",
        "        \"filepath_or_buffer\": preds_fname,\n",
        "        \"names\": [\"id\", \"pred\"],\n",
        "        \"sep\": '\\t',\n",
        "    }\n",
        "\n",
        "    pred_ids = list(read_csv(**kwargs, usecols=[\"id\"])[\"id\"])\n",
        "\n",
        "    pred_y = {\n",
        "        pred_id: [y]\n",
        "        for pred_id, y in zip(\n",
        "            pred_ids, read_csv(**kwargs, usecols=[\"pred\"])[\"pred\"]\n",
        "        )\n",
        "    }\n",
        "\n",
        "    for y in pred_y.values():\n",
        "        assert len(y) == top_k\n",
        "\n",
        "    return pred_ids, pred_y\n",
        "\n",
        "\n",
        "def compute_hit_k(preds, k=10):\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "def compute_mrr(preds):\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "def compute_acc_1(preds, true):\n",
        "    right_answers = 0\n",
        "    bonus = 0\n",
        "    for pred, y in zip(preds, true):\n",
        "        if pred[0] == y:\n",
        "            right_answers += 1\n",
        "        elif pred[0] != pred[0] and y == 'нань':\n",
        "            #print('Your test file contained empty string, skipping %f and %s' % (pred[0], y))\n",
        "            bonus += 1 # bugfix: skip empty line in test\n",
        "    return right_answers / (len(preds) - bonus)\n",
        "\n",
        "\n",
        "def score(preds, true):\n",
        "    assert len(preds) == len(true), 'inconsistent amount of predictions and ground truth answers'\n",
        "    acc_1 = compute_acc_1(preds, true)\n",
        "    return {'acc@1': acc_1}\n",
        "\n",
        "\n",
        "def score_preds(preds_path, data_dir, parts=SCORED_PARTS):\n",
        "    part2iy = load_transliterations_only(data_dir, parts=parts)\n",
        "    pred_ids, pred_dict = load_preds(preds_path)\n",
        "    # pred_dict = {i:y for i,y in zip(pred_ids, pred_y)}\n",
        "    scores = {}\n",
        "    for part, (true_ids, true_y) in part2iy.items():\n",
        "        if true_y is None:\n",
        "            print('no labels for %s set' % part)\n",
        "            continue\n",
        "        pred_y = [pred_dict[i] for i in true_ids]\n",
        "        score_values = score(pred_y, true_y)\n",
        "        acc_1 = score_values['acc@1']\n",
        "        print('%s set accuracy@1: %.2f' % (part, acc_1))\n",
        "        scores[part] = score_values\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwXaPC4LiUMe"
      },
      "source": [
        "## Transformer-based approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM-9cKhbidfl"
      },
      "source": [
        "\n",
        "To implement your algorithm, use the template code, which needs to be modified.\n",
        "\n",
        "First, you need to add some details in the code of the Transformer architecture, implement the methods of the class `LrScheduler`, which is responsible for updating the learning rate during training.\n",
        "Next, you need to select the hyperparameters for the model according to the proposed guide."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nePd6qR5_sC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9136a7e5-5752-443e-b744-d275b118ce11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Levenshtein\n",
            "  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.26.1 rapidfuzz-3.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LQ5sfyjhBawp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools as it\n",
        "import collections as col\n",
        "import random\n",
        "import os\n",
        "import copy\n",
        "import json\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import datetime, time\n",
        "\n",
        "import copy\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as torch_data\n",
        "import itertools as it\n",
        "import collections as col\n",
        "import random\n",
        "\n",
        "import Levenshtein as le"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6enjcHrD_0Y"
      },
      "source": [
        "### Load dataset and embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RmWG0dDUCFto"
      },
      "outputs": [],
      "source": [
        "def load_datasets(data_dir_path, parts):\n",
        "    datasets = {}\n",
        "    for part in parts:\n",
        "        path = os.path.join(data_dir_path, f'{part}.tsv')\n",
        "        datasets[part] = pd.read_csv(path, sep='\\t', na_filter=False)\n",
        "        print(f'Loaded {part} dataset, length: {len(datasets[part])}')\n",
        "    return datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-gMDFNVt-nMw"
      },
      "outputs": [],
      "source": [
        "class TextEncoder:\n",
        "    def __init__(self, load_dir_path=None):\n",
        "        self.lang_keys = ['en', 'ru']\n",
        "        self.directions = ['id2token', 'token2id']\n",
        "        self.service_token_names = {\n",
        "            'pad_token': '<pad>',\n",
        "            'start_token': '<start>',\n",
        "            'unk_token': '<unk>',\n",
        "            'end_token': '<end>'\n",
        "        }\n",
        "        service_id2token = dict(enumerate(self.service_token_names.values()))\n",
        "        service_token2id ={v:k for k,v in service_id2token.items()}\n",
        "        self.service_vocabs = dict(zip(self.directions,\n",
        "                                       [service_id2token, service_token2id]))\n",
        "        if load_dir_path is None:\n",
        "            self.vocabs = {}\n",
        "            for lk in self.lang_keys:\n",
        "                self.vocabs[lk] = copy.deepcopy(self.service_vocabs)\n",
        "        else:\n",
        "            self.vocabs = self.load_vocabs(load_dir_path)\n",
        "    def load_vocabs(self, load_dir_path):\n",
        "        vocabs = {}\n",
        "        load_path = os.path.join(load_dir_path, 'vocabs')\n",
        "        for lk in self.lang_keys:\n",
        "            vocabs[lk] = {}\n",
        "            for d in self.directions:\n",
        "                columns = d.split('2')\n",
        "                print(lk, d)\n",
        "                df = pd.read_csv(os.path.join(load_path, f'{lk}_{d}'))\n",
        "                vocabs[lk][d] = dict(zip(*[df[c] for c in columns]))\n",
        "        return vocabs\n",
        "\n",
        "    def save_vocabs(self, save_dir_path):\n",
        "        save_path = os.path.join(save_dir_path, 'vocabs')\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        for lk in self.lang_keys:\n",
        "            for d in self.directions:\n",
        "                columns = d.split('2')\n",
        "                pd.DataFrame(data=self.vocabs[lk][d].items(),\n",
        "                    columns=columns).to_csv(os.path.join(save_path, f'{lk}_{d}'),\n",
        "                                                index=False,\n",
        "                                                sep=',')\n",
        "    def make_vocabs(self, data_df):\n",
        "        for lk in self.lang_keys:\n",
        "            tokens = col.Counter(''.join(list(it.chain(*data_df[lk])))).keys()\n",
        "            part_id2t = dict(enumerate(tokens, start=len(self.service_token_names)))\n",
        "            part_t2id = {k:v for v,k in part_id2t.items()}\n",
        "            part_vocabs = [part_id2t, part_t2id]\n",
        "            for i in range(len(self.directions)):\n",
        "                self.vocabs[lk][self.directions[i]].update(part_vocabs[i])\n",
        "\n",
        "        self.src_vocab_size = len(self.vocabs['en']['id2token'])\n",
        "        self.tgt_vocab_size = len(self.vocabs['ru']['id2token'])\n",
        "\n",
        "    def frame(self, sample, start_token=None, end_token=None):\n",
        "        if start_token is None:\n",
        "            start_token=self.service_token_names['start_token']\n",
        "        if end_token is None:\n",
        "            end_token=self.service_token_names['end_token']\n",
        "        return [start_token] + sample + [end_token]\n",
        "    def token2id(self, samples, frame, lang_key):\n",
        "        if frame:\n",
        "            samples = list(map(self.frame, samples))\n",
        "        vocab = self.vocabs[lang_key]['token2id']\n",
        "        return list(map(lambda s:\n",
        "                        [vocab[t] if t in vocab.keys() else vocab[self.service_token_names['unk_token']]\n",
        "                         for t in s], samples))\n",
        "\n",
        "    def unframe(self, sample, start_token=None, end_token=None):\n",
        "        if start_token is None:\n",
        "            start_token=self.service_vocabs['token2id'][self.service_token_names['start_token']]\n",
        "        if end_token is None:\n",
        "            end_token=self.service_vocabs['token2id'][self.service_token_names['end_token']]\n",
        "        pad_token=self.service_vocabs['token2id'][self.service_token_names['pad_token']]\n",
        "        return list(it.takewhile(lambda e: e != end_token and e != pad_token, sample[1:]))\n",
        "    def id2token(self, samples, unframe, lang_key):\n",
        "        if unframe:\n",
        "            samples = list(map(self.unframe, samples))\n",
        "        vocab = self.vocabs[lang_key]['id2token']\n",
        "        return list(map(lambda s:\n",
        "                        [vocab[idx] if idx in vocab.keys() else self.service_token_names['unk_token'] for idx in s], samples))\n",
        "\n",
        "\n",
        "class TranslitData(torch_data.Dataset):\n",
        "    def __init__(self, source_strings, target_strings,\n",
        "                text_encoder):\n",
        "        super(TranslitData, self).__init__()\n",
        "        self.source_strings = source_strings\n",
        "        self.text_encoder = text_encoder\n",
        "        if target_strings is not None:\n",
        "            assert len(source_strings) == len(target_strings)\n",
        "            self.target_strings = target_strings\n",
        "        else:\n",
        "            self.target_strings = None\n",
        "    def __len__(self):\n",
        "        return len(self.source_strings)\n",
        "    def __getitem__(self, idx):\n",
        "        src_str = self.source_strings[idx]\n",
        "        encoder_input = self.text_encoder.token2id([list(src_str)], frame=True, lang_key='en')[0]\n",
        "        if self.target_strings is not None:\n",
        "            tgt_str = self.target_strings[idx]\n",
        "            tmp = self.text_encoder.token2id([list(tgt_str)], frame=True, lang_key='ru')[0]\n",
        "            decoder_input = tmp[:-1]\n",
        "            decoder_target = tmp[1:]\n",
        "            return (encoder_input, decoder_input, decoder_target)\n",
        "        else:\n",
        "            return (encoder_input,)\n",
        "\n",
        "\n",
        "class BatchSampler(torch_data.BatchSampler):\n",
        "    def __init__(self, sampler, batch_size, drop_last, shuffle_each_epoch):\n",
        "        super(BatchSampler, self).__init__(sampler, batch_size, drop_last)\n",
        "        self.batches = []\n",
        "        for b in super(BatchSampler, self).__iter__():\n",
        "            self.batches.append(b)\n",
        "        self.shuffle_each_epoch = shuffle_each_epoch\n",
        "        if self.shuffle_each_epoch:\n",
        "            random.shuffle(self.batches)\n",
        "        self.index = 0\n",
        "        print(f'Batches collected: {len(self.batches)}')\n",
        "    def __iter__(self):\n",
        "        self.index = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self.index == len(self.batches):\n",
        "            if self.shuffle_each_epoch:\n",
        "                random.shuffle(self.batches)\n",
        "            raise StopIteration\n",
        "        else:\n",
        "            batch = self.batches[self.index]\n",
        "            self.index += 1\n",
        "            return batch\n",
        "\n",
        "def collate_fn(batch_list):\n",
        "    '''batch_list can store either 3 components:\n",
        "        encoder_inputs, decoder_inputs, decoder_targets\n",
        "        or single component: encoder_inputs'''\n",
        "    components = list(zip(*batch_list))\n",
        "    batch_tensors = []\n",
        "    for data in components:\n",
        "        max_len = max([len(sample) for sample in data])\n",
        "        #print(f'Maximum length in batch = {max_len}')\n",
        "        sample_tensors = [torch.tensor(s, requires_grad=False, dtype=torch.int64)\n",
        "                         for s in data]\n",
        "        batch_tensors.append(nn.utils.rnn.pad_sequence(\n",
        "            sample_tensors,\n",
        "            batch_first=True, padding_value=0))\n",
        "    return tuple(batch_tensors)\n",
        "\n",
        "\n",
        "def create_dataloader(source_strings, target_strings,\n",
        "                      text_encoder, batch_size,\n",
        "                      shuffle_batches_each_epoch):\n",
        "    '''target_strings parameter can be None'''\n",
        "    dataset = TranslitData(source_strings, target_strings,\n",
        "                                text_encoder=text_encoder)\n",
        "    seq_sampler = torch_data.SequentialSampler(dataset)\n",
        "    batch_sampler = BatchSampler(seq_sampler, batch_size=batch_size,\n",
        "                                drop_last=False,\n",
        "                                shuffle_each_epoch=shuffle_batches_each_epoch)\n",
        "    dataloader = torch_data.DataLoader(dataset,\n",
        "                                       batch_sampler=batch_sampler,\n",
        "                                       collate_fn=collate_fn)\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Qsehb_eERRF"
      },
      "source": [
        "### Metric function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MN4I60GqETB0"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(predicted_strings, target_strings, metrics):\n",
        "    metric_values = {}\n",
        "    for m in metrics:\n",
        "        if m == 'acc@1':\n",
        "            metric_values[m] = sum(predicted_strings == target_strings) / len(target_strings)\n",
        "        elif m =='mean_ld@1':\n",
        "            metric_values[m] =\\\n",
        "                np.mean(list(map(lambda e: le.distance(*e), zip(predicted_strings, target_strings))))\n",
        "        else:\n",
        "            raise ValueError(f'Unknown metric: {m}')\n",
        "    return metric_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiYl5XsdkmZG"
      },
      "source": [
        "###  Positional Encoding [1 Point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkNaSzwrkpf_"
      },
      "source": [
        "As you remember, Transformer treats an input sequence of elements as a time series. Since the Encoder inside the Transformer simultaneously processes the entire input sequence, the information about the position of the element needs to be encoded inside its embedding, since it is not identified in any other way inside the model. That is why the PositionalEncoding layer is used, which sums embeddings with a vector of the same dimension.\n",
        "Let the matrix of these vectors for each position of the time series be denoted as $PE$. Then the elements of the matrix are:\n",
        "\n",
        "$$ PE_{(pos,2i)} = \\sin{(pos/10000^{2i/d_{model}})}$$\n",
        "$$ PE_{(pos,2i+1)} = \\cos{(pos/10000^{2i/d_{model}})}$$\n",
        "\n",
        "where $pos$ - is the position, $i$ - index of the component of the corresponging vector, $d_{model}$ - dimension of each vector. Thus, even components represent sine values, and odd ones represent cosine values with different arguments.\n",
        "\n",
        "To run the test use the following function:\n",
        "\n",
        "`test_positional_encoding()`\n",
        "\n",
        "Make sure that there is no any `AssertionError`!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Rm4g1vybAKZs"
      },
      "outputs": [],
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, hidden_size, vocab_size):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.emb_layer = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.emb_layer(x)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, hidden_size, max_len=512):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, hidden_size, requires_grad=False)\n",
        "        # TODO: implement your code here\n",
        "        pos = torch.arange(0, max_len).unsqueeze(1) #здесь мы объявляем позиции их у нас от 0 до нашей максимальной длинны\n",
        "        div_term = torch.exp(torch.arange(0, hidden_size, 2) * -(math.log(torch.tensor(10000.0)) / hidden_size))\n",
        "        #a^b = exp(b * log(a)), у нас в качетсве a — логарифм от 10000, его надо\n",
        "        #умножить на (2i/d_model). Соответственно 2i это torch.arange(0, hidden_size, 2). Знак минус для того, чтобы возвести в отрицательную степень.\n",
        "        #в следующих строчках по этой причине мы умножаем, а не делим (как в формуле)\n",
        "        pe[:, 0::2] = torch.sin(pos * div_term) #для чётных\n",
        "        pe[:, 1::2] = torch.cos(pos * div_term) #для нечётных (это чтобы они не пересикались между собой)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        # pe shape: (1, max_len, hidden_size)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: shape (batch size, sequence length, hidden size)\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hBk6uxQyCqt-"
      },
      "outputs": [],
      "source": [
        "def test_positional_encoding():\n",
        "    pe = PositionalEncoding(max_len=3, hidden_size=4)\n",
        "    res_1 = torch.tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
        "                           [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
        "                           [ 0.9093, -0.4161,  0.0200,  0.9998]]])\n",
        "    # print(pe.pe - res_1)\n",
        "    assert torch.all(torch.abs(pe.pe - res_1) < 1e-4).item()\n",
        "    print('Test is passed!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwN9Qk_NCw-K",
        "outputId": "81604d60-967d-4cae-af71-40881c014bf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test is passed!\n"
          ]
        }
      ],
      "source": [
        "test_positional_encoding()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g026bdkrEtiQ"
      },
      "source": [
        "### LayerNorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dIMy52O9Es0K"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    \"Layer Normalization layer\"\n",
        "\n",
        "    def __init__(self, hidden_size, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.gain = nn.Parameter(torch.ones(hidden_size))\n",
        "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        #print(mean, std) #закоментировала, так как иначе был большой вывод и всё зависало\n",
        "        return self.gain * (x - mean) / (std + self.eps) + self.bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEpsKqLwE3hB"
      },
      "source": [
        "### SublayerConnection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2yuMxRinE3uH"
      },
      "outputs": [],
      "source": [
        "class SublayerConnection(nn.Module):\n",
        "    \"\"\"\n",
        "    A residual connection followed by a layer normalization.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_size, dropout):\n",
        "        super(SublayerConnection, self).__init__()\n",
        "        self.layer_norm = LayerNorm(hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        return self.layer_norm(x + self.dropout(sublayer(x)))\n",
        "\n",
        "def padding_mask(x, pad_idx=0):\n",
        "    assert len(x.size()) >= 2\n",
        "    return (x != pad_idx).unsqueeze(-2)\n",
        "\n",
        "def look_ahead_mask(size):\n",
        "    \"Mask out the right context\"\n",
        "    attn_shape = (1, size, size)\n",
        "    look_ahead_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
        "    return torch.from_numpy(look_ahead_mask) == 0\n",
        "\n",
        "def compositional_mask(x, pad_idx=0):\n",
        "    pm = padding_mask(x, pad_idx=pad_idx)\n",
        "    seq_length = x.size(-1)\n",
        "    result_mask = pm & \\\n",
        "                  look_ahead_mask(seq_length).type_as(pm.data)\n",
        "    return result_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh86csH_FCyB"
      },
      "source": [
        "### FeedForward [1 Point]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4zy1PNwlGIEX"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, hidden_size, ff_hidden_size, dropout=0.1):\n",
        "        super(FeedForward, self).__init__()\n",
        "        # TODO: MAKE FEED FORWARD\n",
        "        # It goes as linear -> RELU -> Dropout -> Linear\n",
        "        self.pre_linear = nn.Linear(hidden_size, ff_hidden_size) #первый линейный слой увеличить размерность\n",
        "        self.post_linear = nn.Linear(ff_hidden_size, hidden_size) #второй линейный слой возвращает к исходной размерности\n",
        "        self.dropout = nn.Dropout(dropout) #обнуление\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: WRITE CORRECT RETURN\n",
        "        #по схеме выше\n",
        "        x = self.pre_linear(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.post_linear(x)\n",
        "        return x\n",
        "\n",
        "def clone_layer(module, N):\n",
        "    \"Produce N identical layers.\"\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0TeMntIjadpK"
      },
      "outputs": [],
      "source": [
        "def test_FF():\n",
        "    ff = FeedForward(24, 256)\n",
        "    assert(ff.pre_linear.weight.size() == (256, 24))\n",
        "    assert(ff.post_linear.weight.size() == (24, 256))\n",
        "\n",
        "    x = torch.rand(32, 24)\n",
        "    out = ff(x)\n",
        "    assert(out.size() == (32, 24))\n",
        "    print('Test is passed!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMA1EoGcatvk",
        "outputId": "2277c54b-f05a-4b3c-c4a3-380a5ecf2397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test is passed!\n"
          ]
        }
      ],
      "source": [
        "test_FF()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwoQ_X8ylJYN"
      },
      "source": [
        "###  MultiHeadAttention [1.5 Point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYGVEp3mkgNf"
      },
      "source": [
        "\n",
        "Then you are required to implement `attention` method in the class  `MultiHeadAttention`. The MultiHeadAttention layer takes as input  query vectors, key and value vectors for each step of the sequence of matrices  Q,K,V correspondingly. Each key vector, value vector, and query vector is obtained as a result of linear projection using one of three trained vector parameter matrices from the previous layer. This semantics can be represented in the form of formulas:\n",
        "$$\n",
        "Attention(Q, K, V)=softmax\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}\\right) V\\\\\n",
        "$$\n",
        "\n",
        "$$\n",
        "MultiHead(Q, K, V) = Concat\\left(head_1, ... , head_h\\right) W^O\\\\\n",
        "$$\n",
        "\n",
        "$$\n",
        "head_i=Attention\\left(Q W_i^Q, K W_i^K, V W_i^V\\right)\\\\\n",
        "$$\n",
        "$h$ - the number of attention heads - parallel sub-layers for Scaled Dot-Product Attention on a vector of smaller dimension ($d_{k} = d_{q} = d_{v} = d_{model} / h$).\n",
        "The logic of  \\texttt{MultiHeadAttention} is presented in the picture (from original  [paper](https://arxiv.org/abs/1706.03762)):\n",
        "\n",
        "![](https://lilianweng.github.io/lil-log/assets/images/transformer.png)\n",
        "\n",
        "\n",
        "Inside a method `attention` you are required to create a dropout layer from  MultiHeadAttention class constructor. Dropout layer is to be applied directly on the attention weights - the result of softmax operation. Value of drop probability  can be regulated in the train in the `model_config['dropout']['attention']`.\n",
        "\n",
        "The correctness of implementation can be checked with\n",
        "`test_multi_head_attention()`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5q7mpdjnAVHP"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, n_heads, hidden_size, dropout=None):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert hidden_size % n_heads == 0\n",
        "        self.head_hidden_size = hidden_size // n_heads\n",
        "        self.n_heads = n_heads\n",
        "        self.linears = clone_layer(nn.Linear(hidden_size, hidden_size), 4)\n",
        "        self.attn_weights = None\n",
        "        self.dropout = dropout\n",
        "        if self.dropout is not None:\n",
        "            self.dropout_layer = nn.Dropout(p=self.dropout)\n",
        "\n",
        "    def attention(self, query, key, value, mask):\n",
        "        \"\"\"Compute 'Scaled Dot Product Attention'\n",
        "            query, key and value tensors have the same shape:\n",
        "                (batch size, number of heads, sequence length, head hidden size)\n",
        "            mask shape: (batch size, 1, sequence length, sequence length)\n",
        "                '1' dimension value will be broadcasted to number of heads inside your operations\n",
        "            mask should be applied before using softmax to get attn_weights\n",
        "        \"\"\"\n",
        "        ## attn_weights shape: (batch size, number of heads, sequence length, sequence length)\n",
        "        ## output shape: (batch size, number of heads, sequence length, head hidden size)\n",
        "        ## TODO: provide your implementation here\n",
        "        ## don't forget to apply dropout to attn_weights if self.dropout is not None\n",
        "        d_k = query.size(-1) #размерность\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k) #формула, не забываем транспонировать K (в каждом батче своя штука будет происходить)\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9) #если маска запрещает куда-то смотреть\n",
        "\n",
        "        p_attn = F.softmax(scores, dim=-1) #вероятности scores распределены верно\n",
        "\n",
        "        if self.dropout is not None:\n",
        "            p_attn = self.dropout_layer(p_attn) #если есть dropout применяем\n",
        "\n",
        "        output = torch.matmul(p_attn, value) #по формуле умножаем\n",
        "\n",
        "        #raise NotImplementedError\n",
        "        return output, p_attn\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        if mask is not None:\n",
        "            # Same mask applied to all h heads.\n",
        "            mask = mask.unsqueeze(1)\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        # Split vectors for different attention heads (from hidden_size => n_heads x head_hidden_size)\n",
        "        # and do separate linear projection, for separate trainable weights\n",
        "        query, key, value = \\\n",
        "            [l(x).view(batch_size, -1, self.n_heads, self.head_hidden_size).transpose(1, 2)\n",
        "             for l, x in zip(self.linears, (query, key, value))]\n",
        "\n",
        "        x, self.attn_weights = self.attention(query, key, value, mask=mask)\n",
        "        # x shape: (batch size, number of heads, sequence length, head hidden size)\n",
        "        # self.attn_weights shape: (batch size, number of heads, sequence length, sequence length)\n",
        "\n",
        "        # Concatenate the output of each head\n",
        "        x = x.transpose(1, 2).contiguous() \\\n",
        "            .view(batch_size, -1, self.n_heads * self.head_hidden_size)\n",
        "\n",
        "        return self.linears[-1](x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ExHkza22FCF0"
      },
      "outputs": [],
      "source": [
        "def test_multi_head_attention():\n",
        "    mha = MultiHeadAttention(n_heads=1, hidden_size=5, dropout=None)\n",
        "    # batch_size == 2, sequence length == 3, hidden_size == 5\n",
        "    # query = torch.arange(150).reshape(2, 3, 5)\n",
        "    query = torch.tensor([[[[ 0.64144618, -0.95817388,  0.37432297,  0.58427106,\n",
        "          -0.94668716]],\n",
        "        [[-0.23199289,  0.66329209, -0.46507035, -0.54272512,\n",
        "          -0.98640698]],\n",
        "        [[ 0.07546638, -0.09277002,  0.20107185, -0.97407381,\n",
        "          -0.27713414]]],\n",
        "       [[[ 0.14727783,  0.4747886 ,  0.44992016, -0.2841419 ,\n",
        "          -0.81820319]],\n",
        "        [[-0.72324994,  0.80643179, -0.47655449,  0.45627872,\n",
        "           0.60942404]],\n",
        "        [[ 0.61712569, -0.62947282, -0.95215713, -0.38721959,\n",
        "          -0.73289725]]]])\n",
        "    key = torch.tensor([[[[-0.81759856, -0.60049991, -0.05923424,  0.51898901,\n",
        "          -0.3366209 ]],\n",
        "        [[ 0.83957818, -0.96361722,  0.62285191,  0.93452467,\n",
        "           0.51219613]],\n",
        "        [[-0.72758847,  0.41256154,  0.00490795,  0.59892503,\n",
        "          -0.07202049]]],\n",
        "       [[[ 0.72315339, -0.49896314,  0.94254637, -0.54356006,\n",
        "          -0.04837949]],\n",
        "        [[ 0.51759322, -0.43927061, -0.59924184,  0.92241702,\n",
        "          -0.86811696]],\n",
        "        [[-0.54322046, -0.92323003, -0.827746  ,  0.90842783,\n",
        "           0.88428119]]]])\n",
        "    value = torch.tensor([[[[-0.83895431,  0.805027  ,  0.22298283, -0.84849915,\n",
        "          -0.34906026]],\n",
        "        [[-0.02899652, -0.17456128, -0.17535998, -0.73160314,\n",
        "          -0.13468061]],\n",
        "        [[ 0.75234265,  0.02675947,  0.84766286, -0.5475651 ,\n",
        "          -0.83319316]]],\n",
        "       [[[-0.47834413,  0.34464645, -0.41921457,  0.33867964,\n",
        "           0.43470836]],\n",
        "        [[-0.99000979,  0.10220893, -0.4932273 ,  0.95938905,\n",
        "           0.01927012]],\n",
        "        [[ 0.91607137,  0.57395644, -0.90914179,  0.97212912,\n",
        "           0.33078759]]]])\n",
        "    query = query.float().transpose(1,2)\n",
        "    key = key.float().transpose(1,2)\n",
        "    value = value.float().transpose(1,2)\n",
        "\n",
        "    x,_ = torch.max(query[:,0,:,:], axis=-1)\n",
        "    mask = compositional_mask(x)\n",
        "    mask.unsqueeze_(1)\n",
        "    for n,t in [('query', query), ('key', key), ('value', value), ('mask', mask)]:\n",
        "        print(f'Name: {n}, shape: {t.size()}')\n",
        "    with torch.no_grad():\n",
        "        output, attn_weights = mha.attention(query, key, value, mask=mask)\n",
        "    assert output.size() == torch.Size([2,1,3,5])\n",
        "    assert attn_weights.size() == torch.Size([2,1,3,3])\n",
        "\n",
        "    truth_output = torch.tensor([[[[-0.8390,  0.8050,  0.2230, -0.8485, -0.3491],\n",
        "          [-0.6043,  0.5212,  0.1076, -0.8146, -0.2870],\n",
        "          [-0.0665,  0.2461,  0.3038, -0.7137, -0.4410]]],\n",
        "        [[[-0.4783,  0.3446, -0.4192,  0.3387,  0.4347],\n",
        "          [-0.7959,  0.1942, -0.4652,  0.7239,  0.1769],\n",
        "          [-0.3678,  0.2868, -0.5799,  0.7987,  0.2086]]]])\n",
        "    truth_attn_weights = torch.tensor([[[[1.0000, 0.0000, 0.0000],\n",
        "          [0.7103, 0.2897, 0.0000],\n",
        "          [0.3621, 0.3105, 0.3274]]],\n",
        "        [[[1.0000, 0.0000, 0.0000],\n",
        "          [0.3793, 0.6207, 0.0000],\n",
        "          [0.2642, 0.4803, 0.2555]]]])\n",
        "    # print(torch.abs(output - truth_output))\n",
        "    # print(torch.abs(attn_weights - truth_attn_weights))\n",
        "    assert torch.all(torch.abs(output - truth_output) < 1e-4).item()\n",
        "    assert torch.all(torch.abs(attn_weights - truth_attn_weights) < 1e-4).item()\n",
        "    print('Test is passed!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GI6yMbX8FhGZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e58984-2742-405c-9b5b-e3798dc55025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: query, shape: torch.Size([2, 1, 3, 5])\n",
            "Name: key, shape: torch.Size([2, 1, 3, 5])\n",
            "Name: value, shape: torch.Size([2, 1, 3, 5])\n",
            "Name: mask, shape: torch.Size([2, 1, 3, 3])\n",
            "Test is passed!\n"
          ]
        }
      ],
      "source": [
        "test_multi_head_attention()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUdLLSojGJbM"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dFMMTX4NA0KP"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
        "\n",
        "    def __init__(self, hidden_size, ff_hidden_size, n_heads, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(n_heads, hidden_size,\n",
        "                                            dropout=dropout['attention'])\n",
        "        self.feed_forward = FeedForward(hidden_size, ff_hidden_size,\n",
        "                                        dropout=dropout['relu'])\n",
        "        self.sublayers = clone_layer(SublayerConnection(hidden_size, dropout['residual']), 2)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.sublayers[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "        return self.sublayers[1](x, self.feed_forward)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedder = Embedding(config['hidden_size'],\n",
        "                                  config['src_vocab_size'])\n",
        "        self.positional_encoder = PositionalEncoding(config['hidden_size'],\n",
        "                                                     max_len=config['max_src_seq_length'])\n",
        "        self.embedding_dropout = nn.Dropout(p=config['dropout']['embedding'])\n",
        "        self.encoder_layer = EncoderLayer(config['hidden_size'],\n",
        "                                          config['ff_hidden_size'],\n",
        "                                          config['n_heads'],\n",
        "                                          config['dropout'])\n",
        "        self.layers = clone_layer(self.encoder_layer, config['n_layers'])\n",
        "        self.layer_norm = LayerNorm(config['hidden_size'])\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"Pass the input (and mask) through each layer in turn.\"\n",
        "        x = self.embedding_dropout(self.positional_encoder(self.embedder(x)))\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.layer_norm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kyeSkMeGQo_"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "B4pSnS8NGPyf"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder is made of 3 sublayers: self attention, encoder-decoder attention\n",
        "    and feed forward\"\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_size, ff_hidden_size, n_heads, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(n_heads, hidden_size,\n",
        "                                            dropout=dropout['attention'])\n",
        "        self.encdec_attn = MultiHeadAttention(n_heads, hidden_size,\n",
        "                                              dropout=dropout['attention'])\n",
        "        self.feed_forward = FeedForward(hidden_size, ff_hidden_size,\n",
        "                                        dropout=dropout['relu'])\n",
        "        self.sublayers = clone_layer(SublayerConnection(hidden_size, dropout['residual']), 3)\n",
        "\n",
        "    def forward(self, x, encoder_output, encoder_mask, decoder_mask):\n",
        "        x = self.sublayers[0](x, lambda x: self.self_attn(x, x, x, decoder_mask))\n",
        "        x = self.sublayers[1](x, lambda x: self.encdec_attn(x, encoder_output,\n",
        "                                                            encoder_output, encoder_mask))\n",
        "        return self.sublayers[2](x, self.feed_forward)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedder = Embedding(config['hidden_size'],\n",
        "                                  config['tgt_vocab_size'])\n",
        "        self.positional_encoder = PositionalEncoding(config['hidden_size'],\n",
        "                                                     max_len=config['max_tgt_seq_length'])\n",
        "        self.embedding_dropout = nn.Dropout(p=config['dropout']['embedding'])\n",
        "        self.decoder_layer = DecoderLayer(config['hidden_size'],\n",
        "                                          config['ff_hidden_size'],\n",
        "                                          config['n_heads'],\n",
        "                                          config['dropout'])\n",
        "        self.layers = clone_layer(self.decoder_layer, config['n_layers'])\n",
        "        self.layer_norm = LayerNorm(config['hidden_size'])\n",
        "\n",
        "    def forward(self, x, encoder_output, encoder_mask, decoder_mask):\n",
        "        x = self.embedding_dropout(self.positional_encoder(self.embedder(x)))\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output, encoder_mask, decoder_mask)\n",
        "        return self.layer_norm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwP_NVeYGY-j"
      },
      "source": [
        "### Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mVTRK_5cGYYa"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.config = config\n",
        "        self.encoder = Encoder(config)\n",
        "        self.decoder = Decoder(config)\n",
        "        self.proj = nn.Linear(config['hidden_size'], config['tgt_vocab_size'])\n",
        "\n",
        "        self.pad_idx = config['pad_idx']\n",
        "        self.tgt_vocab_size = config['tgt_vocab_size']\n",
        "\n",
        "    def encode(self, encoder_input, encoder_input_mask):\n",
        "        return self.encoder(encoder_input, encoder_input_mask)\n",
        "\n",
        "    def decode(self, encoder_output, encoder_input_mask, decoder_input, decoder_input_mask):\n",
        "        return self.decoder(decoder_input, encoder_output, encoder_input_mask, decoder_input_mask)\n",
        "\n",
        "    def linear_project(self, x):\n",
        "        return self.proj(x)\n",
        "\n",
        "    def forward(self, encoder_input, decoder_input):\n",
        "        encoder_input_mask = padding_mask(encoder_input, pad_idx=self.config['pad_idx'])\n",
        "        decoder_input_mask = compositional_mask(decoder_input, pad_idx=self.config['pad_idx'])\n",
        "        encoder_output = self.encode(encoder_input, encoder_input_mask)\n",
        "        decoder_output = self.decode(encoder_output, encoder_input_mask,\n",
        "                                     decoder_input, decoder_input_mask)\n",
        "        output_logits = self.linear_project(decoder_output)\n",
        "        return output_logits\n",
        "\n",
        "\n",
        "def prepare_model(config):\n",
        "    model = Transformer(config)\n",
        "\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnmPBcVyrR6h"
      },
      "source": [
        "####  LrScheduler [1 Point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2luuBDZFrTj1"
      },
      "source": [
        "The last thing you have to prepare is the class  `LrScheduler`, which is in charge of  learning rate updating after every step of the optimizer. You are required to fill the class constructor and the method `learning_rate`. The preferable stratagy of updating the learning rate (lr), is the following two stages:\n",
        "\n",
        "* \"warmup\" stage - lr linearly increases until the defined value during the fixed number of steps (the proportion of all training steps - the parameter `train_config['warmup\\_steps\\_part']` in the train function).\n",
        "* \"decrease\" stage - lr linearly decreases until 0 during the left training steps.\n",
        "\n",
        "`learning_rate()` call should return the value of  lr at this step,  which number is stored at self.step. The class constructor takes not only `warmup_steps_part` but the peak learning rate value `lr_peak` at the end of \"warmup\" stage and a string name of the strategy of learning rate scheduling. You can test other strategies if you want to with `self.type attribute`.\n",
        "\n",
        "Correctness check: `test_lr_scheduler()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "YDvKYF5EAdnX"
      },
      "outputs": [],
      "source": [
        "class LrScheduler:\n",
        "    def __init__(self, n_steps, **kwargs):\n",
        "        self.type = kwargs['type']\n",
        "        self.n_steps = n_steps #добавила эту строчку с общим количеством шагов\n",
        "        if self.type == 'warmup,decay_linear':\n",
        "            ## TODO: provide your implementation here\n",
        "            #raise NotImplementedError\n",
        "            self.warmup_steps_part = kwargs['warmup_steps_part']  #это доля шагов, которую мы задаём (фиксированно)\n",
        "            self.lr_peak = kwargs['lr_peak']  #максимальное значение тоже задаём\n",
        "\n",
        "            # Рассчитываем количество шагов warmup и оставшихся шагов.\n",
        "            self.warmup_steps = int(self.n_steps * self.warmup_steps_part)  #определим,\n",
        "                                                #сколько шагов в соответствии со значением потратим на warmup\n",
        "            self.decrease_steps = self.n_steps - self.warmup_steps  #это оставшиеся шаги, которые потратим на уменьшение\n",
        "        else:\n",
        "            raise ValueError(f'Unknown type argument: {self.type}')\n",
        "        self._step = 0\n",
        "        self._lr = 0\n",
        "\n",
        "    def step(self, optimizer):\n",
        "        self._step += 1\n",
        "        lr = self.learning_rate()\n",
        "        for p in optimizer.param_groups:\n",
        "            p['lr'] = lr\n",
        "\n",
        "    def learning_rate(self, step=None):\n",
        "        if step is None:\n",
        "            step = self._step\n",
        "        if self.type == 'warmup,decay_linear':\n",
        "            ## TODO: provide your implementation here\n",
        "            #raise NotImplementedError\n",
        "            if step <= self.warmup_steps:  #смотрим на номер шага, если он в warmup => надо линейно увеличивать\n",
        "                                           #y = kx+b, то есть lr=k*step +сдвиг\n",
        "                                           #сдвига нет у нас, а k = lr_peak/warmup_steps\n",
        "                return self.lr_peak * step / self.warmup_steps\n",
        "            elif step <= self.n_steps:  #если он в decrease => линейно уменьшать\n",
        "                                        #lr=k*(step-warmup_step) + b\n",
        "                                        #step-warmup_step — номер шага в decrease\n",
        "                                        #b = lr_peak (не делаем скачков и начинаем уменьшать сразу)\n",
        "                                        #k = -lr_peak/decrease_steps\n",
        "                return self.lr_peak * (1 - (step - self.warmup_steps) / self.decrease_steps)\n",
        "            else:  #больше общего количества шагов\n",
        "                return 0\n",
        "        return self._lr\n",
        "\n",
        "    def state_dict(self):\n",
        "        sd = copy.deepcopy(self.__dict__)\n",
        "        return sd\n",
        "\n",
        "    def load_state_dict(self, sd):\n",
        "        for k in sd.keys():\n",
        "            self.__setattr__(k, sd[k])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4JHOgJDBGjhr"
      },
      "outputs": [],
      "source": [
        "def test_lr_scheduler():\n",
        "    lrs_type = 'warmup,decay_linear'\n",
        "    warmup_steps_part =  0.1\n",
        "    lr_peak = 3e-4\n",
        "    sch = LrScheduler(100, type=lrs_type, warmup_steps_part=warmup_steps_part,\n",
        "                      lr_peak=lr_peak)\n",
        "    assert sch.learning_rate(step=5) - 15e-5 < 1e-6\n",
        "    assert sch.learning_rate(step=10) - 3e-4 < 1e-6\n",
        "    assert sch.learning_rate(step=50) - 166e-6 < 1e-6\n",
        "    assert sch.learning_rate(step=100) - 0. < 1e-6\n",
        "    print('Test is passed!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "H2Ys4DZRGmzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619c06e4-e380-40ae-a87e-950ab233d166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test is passed!\n"
          ]
        }
      ],
      "source": [
        "test_lr_scheduler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byCY6Tn-A9i_"
      },
      "source": [
        "### Run and translate [0.5 Points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "-K7-KJEGA8po"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "\n",
        "def run_epoch(data_iter, model, lr_scheduler, optimizer, device, verbose=False):\n",
        "    start = time.time()\n",
        "    local_start = start\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "    tokens = 0\n",
        "    # TODO: TAKE CROSS ENTROPY LOSS WITH SUM REDUCTION\n",
        "    loss_fn = torch.nn.CrossEntropyLoss(reduction='sum')\n",
        "    for i, batch in tqdm(enumerate(data_iter), disable=True): #при общем taqdm во множество строк превращается\n",
        "        encoder_input = batch[0].to(device)\n",
        "        decoder_input = batch[1].to(device)\n",
        "        decoder_target = batch[2].to(device)\n",
        "        # TODO: OBTAIN MODEL LOGITS, PASS THEM TO LOSS_FN AND CALCULATE LOSS\n",
        "        logits = model(encoder_input, decoder_input)\n",
        "        loss = loss_fn(logits.view(-1, logits.size(-1)), decoder_target.view(-1))\n",
        "        #возьмём logits, размерность подправим и возьмём соответствующие метки\n",
        "        total_loss += loss.item()\n",
        "        batch_n_tokens = (decoder_target != model.pad_idx).sum().item()\n",
        "        total_tokens += batch_n_tokens\n",
        "        if optimizer is not None:\n",
        "            optimizer.zero_grad()\n",
        "            lr_scheduler.step(optimizer)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        tokens += batch_n_tokens\n",
        "        if verbose and i % 1000 == 1:\n",
        "            elapsed = time.time() - local_start\n",
        "            print(\"batch number: %d, accumulated average loss: %f, tokens per second: %f\" %\n",
        "                  (i, total_loss / total_tokens, tokens / elapsed))\n",
        "            local_start = time.time()\n",
        "            tokens = 0\n",
        "\n",
        "    average_loss = total_loss / total_tokens\n",
        "    print('** End of epoch, accumulated average loss = %f **' % average_loss)\n",
        "    epoch_elapsed_time = format_time(time.time() - start)\n",
        "    print(f'** Elapsed time: {epoch_elapsed_time}**')\n",
        "    return average_loss\n",
        "\n",
        "\n",
        "def save_checkpoint(epoch, model, lr_scheduler, optimizer, model_dir_path):\n",
        "    save_path = os.path.join(model_dir_path, f'cpkt_{epoch}_epoch')\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'lr_scheduler_state_dict': lr_scheduler.state_dict()\n",
        "    }, save_path)\n",
        "    print(f'Saved checkpoint to {save_path}')\n",
        "\n",
        "def load_model(epoch, model_dir_path):\n",
        "    save_path = os.path.join(model_dir_path, f'cpkt_{epoch}_epoch')\n",
        "    checkpoint = torch.load(save_path)\n",
        "    with open(os.path.join(model_dir_path, 'model_config.json'), 'r', encoding='utf-8') as rf:\n",
        "        model_config = json.load(rf)\n",
        "    model = prepare_model(model_config)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    return model\n",
        "\n",
        "def greedy_decode(model, device, encoder_input, max_len, start_symbol):\n",
        "    batch_size = encoder_input.size()[0]\n",
        "    decoder_input = torch.ones(batch_size, 1).fill_(start_symbol).type_as(encoder_input.data).to(device)\n",
        "\n",
        "    for i in range(max_len):\n",
        "        logits = model(encoder_input, decoder_input)\n",
        "\n",
        "        _, predicted_ids = torch.max(logits, dim=-1)\n",
        "        next_word = predicted_ids[:, i]\n",
        "        # print(next_word)\n",
        "        rest = torch.ones(batch_size, 1).type_as(decoder_input.data)\n",
        "        # print(rest[:,0].size(), next_word.size())\n",
        "        rest[:, 0] = next_word\n",
        "        decoder_input = torch.cat([decoder_input, rest], dim=1).to(device)\n",
        "        # print(decoder_input)\n",
        "    return decoder_input\n",
        "\n",
        "def generate_predictions(dataloader, max_decoding_len, text_encoder, model, device):\n",
        "    # print(f'Max decoding length = {max_decoding_len}')\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    start_token_id = text_encoder.service_vocabs['token2id'][\n",
        "        text_encoder.service_token_names['start_token']]\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader):\n",
        "            encoder_input = batch[0].to(device)\n",
        "            prediction_tensor = \\\n",
        "                greedy_decode(model, device, encoder_input, max_decoding_len,\n",
        "                              start_token_id)\n",
        "\n",
        "            predictions.extend([''.join(e) for e in text_encoder.id2token(prediction_tensor.cpu().numpy(),\n",
        "                                                                          unframe=True, lang_key='ru')])\n",
        "    return np.array(predictions)\n",
        "\n",
        "\n",
        "def train(source_strings, target_strings, model_config=None, train_config=None):\n",
        "    '''Common training cycle for final run (fixed hyperparameters,\n",
        "    no evaluation during training)'''\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print(f'Using GPU device: {device}')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print(f'GPU is not available, using CPU device {device}')\n",
        "\n",
        "    train_df = pd.DataFrame({'en': source_strings, 'ru': target_strings})\n",
        "    text_encoder = TextEncoder()\n",
        "    text_encoder.make_vocabs(train_df)\n",
        "\n",
        "    # TODO: MOVE CONFIG TO ARGUMENTS\n",
        "    if model_config is None: #если model_config не передали\n",
        "      model_config = {\n",
        "          'src_vocab_size': text_encoder.src_vocab_size,\n",
        "          'tgt_vocab_size': text_encoder.tgt_vocab_size,\n",
        "          'max_src_seq_length': max(train_df['en'].aggregate(len)) + 2, #including start_token and end_token\n",
        "          'max_tgt_seq_length': max(train_df['ru'].aggregate(len)) + 2,\n",
        "          'n_layers': 2,\n",
        "          'n_heads': 2,\n",
        "          'hidden_size': 128,\n",
        "          'ff_hidden_size': 256,\n",
        "          'dropout': {\n",
        "              'embedding': 0.1,\n",
        "              'attention': 0.1,\n",
        "              'residual': 0.1,\n",
        "              'relu': 0.1\n",
        "          },\n",
        "          'pad_idx': 0\n",
        "      }\n",
        "    else: #поскольку здесь находится text_encoder, чтобы его ещё и вне добавлять\n",
        "          #сделала вот так, добавляя необходимые значения к тому, что передадим в функцию\n",
        "      model_config['src_vocab_size'] = text_encoder.src_vocab_size\n",
        "      model_config['tgt_vocab_size'] = text_encoder.tgt_vocab_size\n",
        "      model_config['max_src_seq_length'] = max(train_df['en'].aggregate(len)) + 2\n",
        "      model_config['max_tgt_seq_length'] = max(train_df['ru'].aggregate(len)) + 2\n",
        "\n",
        "    model = prepare_model(model_config)\n",
        "    model.to(device)\n",
        "\n",
        "    # TODO: MOVE CONFIG TO ARGUMENTS\n",
        "    if train_config is None: #если train_config не передали\n",
        "      train_config = {'batch_size': 200, 'n_epochs': 1, 'lr_scheduler': {\n",
        "          'type': 'warmup,decay_linear',\n",
        "          'warmup_steps_part': 0.1,\n",
        "          'lr_peak': 3e-4,\n",
        "      }}\n",
        "\n",
        "    #Model training procedure\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.)\n",
        "    n_steps = (len(train_df) // train_config['batch_size'] + 1) * train_config['n_epochs']\n",
        "    lr_scheduler = LrScheduler(n_steps, **train_config['lr_scheduler'])\n",
        "\n",
        "    # prepare train data\n",
        "    source_strings, target_strings = zip(*sorted(zip(source_strings, target_strings),\n",
        "                                                 key=lambda e: len(e[0])))\n",
        "    train_dataloader = create_dataloader(source_strings, target_strings, text_encoder,\n",
        "                                         train_config['batch_size'],\n",
        "                                         shuffle_batches_each_epoch=True)\n",
        "    # training cycle\n",
        "    for epoch in range(1,train_config['n_epochs']+1):\n",
        "        print('\\n' + '-'*40)\n",
        "        print(f'Epoch: {epoch}')\n",
        "        print(f'Run training...')\n",
        "        model.train()\n",
        "        run_epoch(train_dataloader, model,\n",
        "                  lr_scheduler, optimizer, device=device, verbose=False)\n",
        "    learnable_params = {\n",
        "        'model': model,\n",
        "        'text_encoder': text_encoder,\n",
        "    }\n",
        "    return learnable_params\n",
        "\n",
        "def classify(source_strings, learnable_params):\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print(f'Using GPU device: {device}')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print(f'GPU is not available, using CPU device {device}')\n",
        "\n",
        "    model = learnable_params['model']\n",
        "    text_encoder = learnable_params['text_encoder']\n",
        "    batch_size = 200\n",
        "    dataloader = create_dataloader(source_strings, None, text_encoder,\n",
        "                                   batch_size, shuffle_batches_each_epoch=False)\n",
        "    max_decoding_len = model.config['max_tgt_seq_length']\n",
        "    predictions = generate_predictions(dataloader, max_decoding_len, text_encoder, model, device)\n",
        "    #return single top1 prediction for each sample\n",
        "    return np.expand_dims(predictions, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpG6i8X-HMmF"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "f-7-YtzEKnug"
      },
      "outputs": [],
      "source": [
        "PREDS_FNAME = \"preds_translit.tsv\"\n",
        "SCORED_PARTS = ('train', 'dev', 'train_small', 'dev_small', 'test')\n",
        "TRANSLIT_PATH = \"TRANSLIT\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "74GcLUTuLFyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8024b12-6ec6-4033-a25d-095b183f045b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training classifier on 105371 examples from train set ...\n",
            "Using GPU device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-a7590c1f4dd9>:122: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
            "  'max_src_seq_length': max(train_df['en'].aggregate(len)) + 2, #including start_token and end_token\n",
            "<ipython-input-28-a7590c1f4dd9>:123: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
            "  'max_tgt_seq_length': max(train_df['ru'].aggregate(len)) + 2,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batches collected: 527\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 1\n",
            "Run training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "527it [00:28, 18.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** End of epoch, accumulated average loss = 3.154407 **\n",
            "** Elapsed time: 0:00:28**\n",
            "Classifier trained in 42.81s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "top_k = 1\n",
        "part2ixy = load_dataset(TRANSLIT_PATH, parts=SCORED_PARTS)\n",
        "\n",
        "train_ids, train_strings, train_transliterations = part2ixy['train']\n",
        "print('\\nTraining classifier on %d examples from train set ...' % len(train_strings))\n",
        "st = time.time()\n",
        "params = train(train_strings, train_transliterations)\n",
        "print('Classifier trained in %.2fs' % (time.time() - st))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hPELZcXeHLHF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452221ad-cd4b-4a3d-d438-50164d97f884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classifying train set with 105371 examples ...\n",
            "Using GPU device: cuda\n",
            "Batches collected: 527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 527/527 [01:26<00:00,  6.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set classified in 86.31s\n",
            "\n",
            "Classifying dev set with 26342 examples ...\n",
            "Using GPU device: cuda\n",
            "Batches collected: 132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 132/132 [00:21<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev set classified in 21.30s\n",
            "\n",
            "Classifying train_small set with 2000 examples ...\n",
            "Using GPU device: cuda\n",
            "Batches collected: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_small set classified in 1.57s\n",
            "\n",
            "Classifying dev_small set with 2000 examples ...\n",
            "Using GPU device: cuda\n",
            "Batches collected: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev_small set classified in 1.52s\n",
            "\n",
            "Classifying test set with 32926 examples ...\n",
            "Using GPU device: cuda\n",
            "Batches collected: 165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 165/165 [00:26<00:00,  6.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set classified in 26.36s\n",
            "Predictions saved to preds_translit.tsv\n",
            "\n",
            "Checking saved predictions ...\n",
            "train set accuracy@1: 0.00\n",
            "dev set accuracy@1: 0.00\n",
            "train_small set accuracy@1: 0.00\n",
            "dev_small set accuracy@1: 0.00\n",
            "no labels for test set\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'acc@1': 9.490277210997334e-05},\n",
              " 'dev': {'acc@1': 7.592437931819907e-05},\n",
              " 'train_small': {'acc@1': 0.0},\n",
              " 'dev_small': {'acc@1': 0.0}}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "allpreds = []\n",
        "for part, (ids, x, y) in part2ixy.items():\n",
        "    print('\\nClassifying %s set with %d examples ...' % (part, len(x)))\n",
        "    st = time.time()\n",
        "    preds = classify(x, params)\n",
        "    print('%s set classified in %.2fs' % (part, time.time() - st))\n",
        "    count_of_values = list(map(len, preds))\n",
        "    assert np.all(np.array(count_of_values) == top_k)\n",
        "    #score(preds, y)\n",
        "    allpreds.extend(zip(ids, preds))\n",
        "\n",
        "save_preds(allpreds, preds_fname=PREDS_FNAME)\n",
        "print('\\nChecking saved predictions ...')\n",
        "score_preds(preds_path=PREDS_FNAME, data_dir=TRANSLIT_PATH, parts=SCORED_PARTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFfDH0-SsRm-"
      },
      "source": [
        "###  Hyper-parameters choice [5 Points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxqZbEmtsV0g"
      },
      "source": [
        "The model is ready. Now we need to find the optimal hyper-parameters.\n",
        "\n",
        "The quality of models with different hyperparameters should be monitored on dev or on dev_small samples (in order to save time, since generating transliterations is a rather time-consuming process, comparable to one training epoch).\n",
        "\n",
        "To generate predictions, you can use the `generate_predictions` function, to calculate the accuracy@1 metric, and then you can use the `compute_metrics` function.\n",
        "\n",
        "\n",
        "\n",
        "Hyper-parameters are stored in the dictionary `model_config` and `train_config` in train function. The following hyperparameters in `model_config` and `train_config` are suggested to leave unmodified:\n",
        "\n",
        "* n_layers $=$ 2\n",
        "* n_heads $=$ 2\n",
        "* hidden_size $=$ 128\n",
        "* fc_hidden_size $=$ 256\n",
        "* warmup_steps_part $=$ 0.1\n",
        "* batch_size $=$ 200\n",
        "\n",
        " You can vary the dropout value. The model has 4 types of : ***embedding dropout*** applied on embdeddings before sending to the first layer of  Encoder or Decoder, ***attention*** dropout applied on the attention weights in the MultiHeadAttention layer, ***residual dropout*** applied on the output of each sublayer (MultiHeadAttention or FeedForward) in layers Encoder and Decoder and, finaly, ***relu dropout*** in used in FeedForward layer. For all 4 types it is suggested to test the same value of dropout from the list: 0.1, 0.15, 0.2.\n",
        " Also it is suggested to test several peak levels of learning rate - **lr_peak** : 5e-4, 1e-3, 2e-3.\n",
        "\n",
        "Note that if you are using a GPU, then training one epoch takes about 1 minute, and up to 1 GB of video memory is required. When using the CPU, the learning speed slows down by about 2 times. If there are problems with insufficient RAM / video memory, reduce the batch size, but in this case the optimal range of learning rate values will change, and it must be determined again. To train a model with  batch_size $=$ 200 , it will take at least 300 epochs to achieve accuracy 0.66 on dev_small dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQXVmzk0a60Y"
      },
      "source": [
        "*Question: What are the optimal hyperpameters according to your experiments? Add plots or other descriptions here.*\n",
        "\n",
        "```\n",
        "\n",
        "ENTER HERE YOUR ANSWER\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для начала надо задать промежутки значений, которые мы будем подбирать, в условии это: 4 типа dropout, каждый со значением [0.1, 0.15, 0.2.] и также ещё есть несколько значений lr_peak [5e-4, 1e-3, 2e-3]\n",
        "\n",
        "В таких случаях подбора параметров обычно использовала PramenerGrid.\n",
        "\n",
        "Ресурсов не очень много, поэтому возтму сразу dev_small.\n",
        "\n",
        "Также надо посмотреть на количество эпох, хоть и написано, что минимум 300 нужно будет, я хочу попробовать и на чуть меньших значениях.\n",
        "\n"
      ],
      "metadata": {
        "id": "iB6HUA9CnTWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid"
      ],
      "metadata": {
        "id": "hrt3vcKpzZYv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config_main = {\n",
        "    'n_layers': 2,\n",
        "    'n_heads': 2,\n",
        "    'hidden_size': 128,\n",
        "    'ff_hidden_size': 256,\n",
        "    'pad_idx': 0\n",
        "}"
      ],
      "metadata": {
        "id": "yJCdzByH3Exe"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_config_main = {\n",
        "    'batch_size': 200,\n",
        "    'lr_scheduler': {\n",
        "        'type': 'warmup,decay_linear',\n",
        "        'warmup_steps_part': 0.1\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "6rQCnPVV3J-X"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'dropout': [0.1, 0.15, 0.2],\n",
        "    'lr_peak': [5e-4, 1e-3, 2e-3],\n",
        "    'n_epochs': [50]\n",
        "}"
      ],
      "metadata": {
        "id": "bM-5Msa65KgN"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []"
      ],
      "metadata": {
        "id": "G6YiWmPe5KkC"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ids, test_strings, test_transliterations = part2ixy['dev_small']"
      ],
      "metadata": {
        "id": "ehM3oJRB7SBH"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for params in ParameterGrid(param_grid):\n",
        "\n",
        "      model_config_main['dropout'] = { #добавим в соответствии с param_grid новые значения\n",
        "          'embedding': params['dropout'],\n",
        "          'attention': params['dropout'],\n",
        "          'residual': params['dropout'],\n",
        "          'relu': params['dropout']\n",
        "      }\n",
        "\n",
        "      train_config_main['lr_scheduler']['lr_peak'] = params['lr_peak']\n",
        "      train_config_main['n_epochs'] = params['n_epochs']\n",
        "\n",
        "      print(f\"Training with dropout={params['dropout']}, lr_peak={params['lr_peak']} and n_epochs={params['n_epochs']}\")\n",
        "\n",
        "      st = time.time()\n",
        "      my_params = train(train_strings, train_transliterations, model_config_main, train_config_main)  #передаём все нужные параметры и обучаем\n",
        "      print('Classifier trained in %.2fs' % (time.time() - st))\n",
        "\n",
        "      #тестируем\n",
        "      print('\\nClassifying dev_small set with %d examples ...' % len(test_strings))\n",
        "      st = time.time()\n",
        "      preds = classify(test_strings, my_params)\n",
        "      print('Predictions generated in in %.2fs' % (time.time() - st))\n",
        "\n",
        "      #вычисляем accuracy@1\n",
        "      accuracy = compute_acc_1(preds, test_transliterations)\n",
        "      print(f\"Accuracy@1: {accuracy}\")\n",
        "\n",
        "      #сохраним результаты\n",
        "      results.append({'dropout': params['dropout'], 'lr_peak': params['lr_peak'], 'accuracy@1': accuracy})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9uI_zx7f5aMy",
        "outputId": "b921fbf6-e1fc-4ec6-c04a-1499dfb8b281"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/9 [00:00<?, ?config/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with dropout=0.1, lr_peak=0.0005 and n_epochs=50\n",
            "Using GPU device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-59-502c5653721e>:140: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
            "  model_config['max_src_seq_length'] = max(train_df['en'].aggregate(len)) + 2\n",
            "<ipython-input-59-502c5653721e>:141: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
            "  model_config['max_tgt_seq_length'] = max(train_df['ru'].aggregate(len)) + 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batches collected: 527\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 1\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 3.892564 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 2\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 2.620715 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 3\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 1.252593 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 4\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.875728 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 5\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.695003 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 6\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.601536 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 7\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.548729 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 8\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.514486 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 9\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.486983 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 10\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.464593 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 11\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.444674 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 12\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.427722 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 13\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.414210 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 14\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.403692 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 15\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.393801 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 16\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.385695 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 17\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.378540 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 18\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.370368 **\n",
            "** Elapsed time: 0:00:18**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 19\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.364683 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 20\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.358469 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 21\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.353928 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 22\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.350023 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 23\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.345872 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 24\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.340683 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 25\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.338549 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 26\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.334683 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 27\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.332177 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 28\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.328915 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 29\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.326467 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 30\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.323629 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 31\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.320548 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 32\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.318134 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 33\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.316717 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 34\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.313582 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 35\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.311328 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 36\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.310382 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 37\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.308693 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 38\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.307315 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 39\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.305795 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 40\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.303334 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 41\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.302587 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 42\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.301378 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 43\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.299999 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 44\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.299151 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 45\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.297493 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 46\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.296748 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 47\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.296325 **\n",
            "** Elapsed time: 0:00:17**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 48\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.294937 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 49\n",
            "Run training...\n",
            "** End of epoch, accumulated average loss = 0.293906 **\n",
            "** Elapsed time: 0:00:16**\n",
            "\n",
            "----------------------------------------\n",
            "Epoch: 50\n",
            "Run training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/9 [13:56<?, ?config/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** End of epoch, accumulated average loss = 0.293993 **\n",
            "** Elapsed time: 0:00:17**\n",
            "Classifier trained in 836.16s\n",
            "\n",
            "Classifying dev_small set with 2000 examples ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "generate_predictions() missing 3 required positional arguments: 'text_encoder', 'model', and 'device'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-e5b9cee6b81e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nClassifying dev_small set with %d examples ...'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_strings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predictions generated in in %.2fs'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: generate_predictions() missing 3 required positional arguments: 'text_encoder', 'model', and 'device'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.append({'dropout': params['dropout'], 'lr_peak': params['lr_peak'], 'accuracy@1': accuracy})"
      ],
      "metadata": {
        "id": "Nuzom60x5aQB"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = compute_acc_1(preds, test_transliterations)"
      ],
      "metadata": {
        "id": "7mlEkgINXwig"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "X_fOzZpJ5aVh"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "XEwNY1tFXnpC"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сортируем результаты\n",
        "results_df = pd.DataFrame(results).sort_values(by='accuracy@1', ascending=False)\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(results_df.head(1))\n",
        "\n",
        "# Визуализация результатов\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=results_df, x=\"lr_peak\", y=\"accuracy@1\", hue=\"dropout\", marker=\"o\", palette=\"viridis\")\n",
        "plt.xscale(\"log\")\n",
        "plt.title(\"Accuracy@1 vs lr_peak for Different Dropout Values\")\n",
        "plt.xlabel(\"Learning Rate Peak (lr_peak)\")\n",
        "plt.ylabel(\"Accuracy@1\")\n",
        "plt.legend(title=\"Dropout\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "pivot = results_df.pivot(\"dropout\", \"lr_peak\", \"accuracy@1\")\n",
        "sns.heatmap(pivot, annot=True, fmt=\".3f\", cmap=\"viridis\", cbar_kws={\"label\": \"Accuracy@1\"})\n",
        "plt.title(\"Accuracy@1 Heatmap\")\n",
        "plt.xlabel(\"Learning Rate Peak (lr_peak)\")\n",
        "plt.ylabel(\"Dropout\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uImxyvLdyg4_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "outputId": "4cedd500-1678-40c6-d271-c06285285fa8"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters:\n",
            "   dropout  lr_peak  accuracy@1\n",
            "0      0.1   0.0005      0.6425\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "DataFrame.pivot() takes 1 positional argument but 4 were given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-4f939bd375c0>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mpivot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lr_peak\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accuracy@1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".3f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"viridis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar_kws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Accuracy@1\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy@1 Heatmap\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: DataFrame.pivot() takes 1 positional argument but 4 were given"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hMYmIO2tf8z"
      },
      "source": [
        "## Label smoothing [1 Point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setYzbjCtqZY"
      },
      "source": [
        "Now imagine that we have a prediction vector from probabilities at position t in the sequence of tokens for each token id from the vocabulary. CrossEntropy compares it with ground truth one-hot representation\n",
        "\n",
        "$$[0, ... 0, 1, 0, ..., 0].$$\n",
        "\n",
        "And now imagine that we are slightly \"smoothed\" the values in the ground truth vector and obtained\n",
        "\n",
        "$$[\\frac{\\alpha}{|V|}, ..., \\frac{\\alpha}{|V|}, 1(1-\\alpha)+\\frac{\\alpha}{|V|},  \\frac{\\alpha}{|V|}, ... \\frac{\\alpha}{|V|}],$$\n",
        "\n",
        "where $\\alpha$ - parameter from 0 to 1, $|V|$ - vocabulary size - number of components in the ground truth vector. The values ​​of this new vector are still summed to 1. Calculate the cross-entropy of our prediction vector and the new ground truth. Now, firstly, cross-entropy will never reach 0, and secondly, the result of the error function will require the model, as usual, to return the highest probability vector compared to other components of the probability vector for the correct token in the dictionary, but at the same time not too large, because as the value of this probability approaches 1, the value of the error function increases. For research on the use of label smoothing, see the [paper](https://arxiv.org/abs/1906.02629).\n",
        "    \n",
        "Accordingly, in order to embed label smoothing into the model, it is necessary to carry out the transformation described above on the ground truth vectors, as well as to implement the cross-entropy calculation, since the used `torch.nn.CrossEntropy` class is not quite suitable, since for the ground truth representation of `__call__` method takes the id of the correct token and builds a one-hot vector already inside. However, it is possible to implement what is required based on the internal implementation of this class [CrossEntropyLoss](https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#CrossEntropyLoss).\n",
        "    \n",
        "\n",
        "Test different values of $\\alpha$ (e.x, 0.05, 0.1, 0.2). Describe your experiments and results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL9V_9-7bVzw"
      },
      "source": [
        "```\n",
        "\n",
        "ENTER HERE YOUR ANSWER\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZU-88SKPj36"
      },
      "outputs": [],
      "source": [
        "# ENTER HERE YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTzR27d4desF"
      },
      "source": [
        "# BONUS: Additional Experiments [Up to 2 Points]\n",
        "\n",
        "Be creative and run additional experiments with changing Transformer Architecture to get better score. You probably would like to dive into\n",
        "\n",
        "1) Reading papers\n",
        "\n",
        "2) Play with Normalization\n",
        "\n",
        "3) Play with Positional Encoding\n",
        "\n",
        "4) Try different Schedulers\n",
        "\n",
        "5) Maybe you would like to alter architecture a lot :)\n",
        "\n",
        "The fair and interesting experiments will be highly rewarded even if the result was not successful. Nevertheless, you need to report them properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jg9hJ6hgeLqf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}